{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Processing jobs\n",
    "\n",
    "With Amazon SageMaker Processing jobs, you can leverage a simplified, managed experience to run data pre- or post-processing and model evaluation workloads on the Amazon SageMaker platform.\n",
    "\n",
    "A processing job downloads input from Amazon Simple Storage Service (Amazon S3), then uploads outputs to Amazon S3 during or after the processing job.\n",
    "\n",
    "This notebook shows how you can:\n",
    "\n",
    "1. Run a processing job to run a scikit-learn script that cleans, pre-processes, performs feature engineering, and splits the input data into train and test sets.\n",
    "2. Run a training job on the pre-processed training data to train a model\n",
    "3. Run a processing job on the pre-processed test data to evaluate the trained model's performance\n",
    "4. Use your own custom container to run processing jobs with your own Python libraries and dependencies.\n",
    "\n",
    "The dataset used here is ..................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapids Toy example on SM Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘docker’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Dockerfile to create the processing container. Install `pandas` and `scikit-learn` into it. You can install your own dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM rapidsai/rapidsai\n",
    "\n",
    "RUN conda install -c anaconda cudatoolkit\n",
    "RUN conda install -c rapidsai -c nvidia -c conda-forge -c defaults rapids=0.13 python=3.6\n",
    "RUN conda install -c conda-forge xgboost\n",
    "RUN conda install -c anaconda pytest\n",
    "RUN conda install scikit-learn xgboost\n",
    "RUN conda install dask\n",
    "RUN conda install -c conda-forge dask-xgboost\n",
    "RUN conda install -c rapidsai dask-cudf\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code builds the container using the `docker` command, creates an Amazon Elastic Container Registry (Amazon ECR) repository, and pushes the image to Amazon ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  2.048kB\n",
      "Step 1/11 : FROM rapidsai/rapidsai\n",
      " ---> 8429180a83ec\n",
      "Step 2/11 : RUN conda install -c anaconda cudatoolkit\n",
      " ---> Using cache\n",
      " ---> 062f50c892c3\n",
      "Step 3/11 : RUN conda install -c rapidsai -c nvidia -c conda-forge -c defaults rapids=0.13 python=3.6\n",
      " ---> Using cache\n",
      " ---> 7b5c698cd10c\n",
      "Step 4/11 : RUN conda install -c conda-forge xgboost\n",
      " ---> Using cache\n",
      " ---> 55afcd0a0739\n",
      "Step 5/11 : RUN conda install -c anaconda pytest\n",
      " ---> Using cache\n",
      " ---> 9eb953647c09\n",
      "Step 6/11 : RUN conda install scikit-learn xgboost\n",
      " ---> Using cache\n",
      " ---> f3a7444c5467\n",
      "Step 7/11 : RUN conda install dask\n",
      " ---> Running in 0b11b860ef61\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Removing intermediate container 0b11b860ef61\n",
      " ---> ada5888f5e5c\n",
      "Step 8/11 : RUN conda install -c conda-forge dask-xgboost\n",
      " ---> Running in 48e835a377b2\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask-xgboost\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates      anaconda::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.4.5.1-hecc5488_0\n",
      "  conda                        anaconda::conda-4.8.3-py36_0 --> conda-forge::conda-4.8.3-py36h9f0ad1d_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi               anaconda::certifi-2020.4.5.1-py36_0 --> conda-forge::certifi-2020.4.5.1-py36h9f0ad1d_0\n",
      "  openssl               anaconda::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Removing intermediate container 48e835a377b2\n",
      " ---> 6640d779aef1\n",
      "Step 9/11 : RUN conda install -c rapidsai dask-cudf\n",
      " ---> Running in defe1cf74cb5\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Removing intermediate container defe1cf74cb5\n",
      " ---> a36ff8780248\n",
      "Step 10/11 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 310d3beeab32\n",
      "Removing intermediate container 310d3beeab32\n",
      " ---> 913cb36430cb\n",
      "Step 11/11 : ENTRYPOINT [\"python3\"]\n",
      " ---> Running in 38eadf90194c\n",
      "Removing intermediate container 38eadf90194c\n",
      " ---> 0ee8f2fbed64\n",
      "Successfully built 0ee8f2fbed64\n",
      "Successfully tagged miniconda-rapids-container-v2:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'miniconda-rapids-container-v2' already exists in the registry with id '497456752804'\n",
      "The push refers to repository [497456752804.dkr.ecr.us-east-1.amazonaws.com/miniconda-rapids-container-v2]\n",
      "\n",
      "\u001b[1B0c8a1f68: Preparing \n",
      "\u001b[1B5aa0a808: Preparing \n",
      "\u001b[1B789a7d42: Preparing \n",
      "\u001b[1Bd4833170: Preparing \n",
      "\u001b[1Bb141c03d: Preparing \n",
      "\u001b[1B3815d341: Preparing \n",
      "\u001b[1Be2cf18e3: Preparing \n",
      "\u001b[1B05814c4c: Preparing \n",
      "\u001b[1B5d86e7c8: Preparing \n",
      "\u001b[1B68149fa6: Preparing \n",
      "\u001b[1B9a3a9de4: Preparing \n",
      "\u001b[1B6ff3b469: Preparing \n",
      "\u001b[7Be2cf18e3: Waiting g \n",
      "\u001b[1Bacbae25f: Preparing \n",
      "\u001b[8B05814c4c: Waiting g \n",
      "\u001b[1B80f86be3: Preparing \n",
      "\u001b[1B8c8d5f39: Preparing \n",
      "\u001b[8B9a3a9de4: Waiting g \n",
      "\u001b[1B9d138968: Preparing \n",
      "\u001b[18B89a7d42: Pushed   61.83MB/61.82MB0A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[20A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[Klatest: digest: sha256:e729754a2c924bc0dd5a886cf9f32c268e27e295bcda1738ddfa5f37f5258790 size: 4541\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'miniconda-rapids-container-v2'\n",
    "tag = ':latest'\n",
    "\n",
    "uri_suffix = 'amazonaws.com'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository docker\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if the container works with SM processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ScriptProcessor` class lets you run a command inside this container, which you can use to run your own script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data = 'https://github.com/plotly/datasets/raw/master/tips.csv'\n",
    "df = pd.read_csv(input_data)\n",
    "df.to_csv('tips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size\n",
       "0         16.99  1.01  Female     No   Sun  Dinner     2\n",
       "1         10.34  1.66    Male     No   Sun  Dinner     3\n",
       "2         21.01  3.50    Male     No   Sun  Dinner     3\n",
       "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
       "4         24.59  3.61  Female     No   Sun  Dinner     4\n",
       "..          ...   ...     ...    ...   ...     ...   ...\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
       "\n",
       "[244 rows x 7 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write toy example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf, io, requests\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('Received arguments {}'.format(args))\n",
    "\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'tips.csv')\n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    \n",
    "    tips_df = cudf.read_csv(input_data_path)\n",
    "    tips_df['tip_percentage'] = tips_df['tip'] / tips_df['total_bill'] * 100\n",
    "\n",
    "    # display average tip by dining party size\n",
    "    print(tips_df.groupby('size').tip_percentage.mean())\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_features.csv')\n",
    "    \n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    tips_df.to_csv(train_features_output_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "script_processor = ScriptProcessor(command=['python'],\n",
    "                image_uri=processing_repository_uri,\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.p3.16xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the same `preprocessing.py` script you ran above, but now, this code is running inside of the Docker container you built in this notebook, not the scikit-learn image maintained by Amazon SageMaker. You can add the dependencies to the Docker image, and run your own pre-processing, feature-engineering, and model evaluation scripts inside of this container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  miniconda-rapids-container-v2-2020-05-19-01-00-37-214\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-19-01-00-37-214/input/input-1/tips.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-19-01-00-37-214/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-19-01-00-37-214/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................................\u001b[34mReceived arguments Namespace(train_test_split_ratio=0.2)\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/tips.csv\u001b[0m\n",
      "\u001b[34m/conda/lib/python3.6/site-packages/fsspec/implementations/local.py:33: FutureWarning: The default value of auto_mkdir=True has been deprecated and will be changed to auto_mkdir=False by default in a future release.\n",
      "  FutureWarning,\u001b[0m\n",
      "\u001b[34msize\u001b[0m\n",
      "\u001b[34m1    21.729202\u001b[0m\n",
      "\u001b[34m2    16.571919\u001b[0m\n",
      "\u001b[34m3    15.215685\u001b[0m\n",
      "\u001b[34m4    14.594901\u001b[0m\n",
      "\u001b[34m5    14.149549\u001b[0m\n",
      "\u001b[34m6    15.622920\u001b[0m\n",
      "\u001b[34mName: tip_percentage, dtype: float64\u001b[0m\n",
      "\u001b[34mSaving training features to /opt/ml/processing/train/train_features.csv\u001b[0m\n",
      "\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-19-01-00-37-214/input/input-1/tips.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-19-01-00-37-214/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-19-01-00-37-214/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]}, 'ProcessingJobName': 'miniconda-rapids-container-v2-2020-05-19-01-00-37-214', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.p3.8xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '497456752804.dkr.ecr.us-east-1.amazonaws.com/miniconda-rapids-container-v2:latest', 'ContainerEntrypoint': ['python', '/opt/ml/processing/input/code/preprocessing.py'], 'ContainerArguments': ['--train-test-split-ratio', '0.2']}, 'RoleArn': 'arn:aws:iam::497456752804:role/service-role/AmazonSageMaker-ExecutionRole-20191209T111054', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:497456752804:processing-job/miniconda-rapids-container-v2-2020-05-19-01-00-37-214', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2020, 5, 19, 1, 8, 2, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2020, 5, 19, 1, 6, 13, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2020, 5, 19, 1, 8, 2, 451000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 5, 19, 1, 0, 37, 629000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'eda7a785-b9b8-4015-a4d9-07043423e72b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'eda7a785-b9b8-4015-a4d9-07043423e72b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1820', 'date': 'Tue, 19 May 2020 01:08:21 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source='tips.csv',\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2']\n",
    "                     )\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGGS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-19 00:10:07--  https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2816407858 (2.6G) [application/x-httpd-php]\n",
      "Saving to: ‘HIGGS.csv.gz’\n",
      "\n",
      "HIGGS.csv.gz        100%[===================>]   2.62G  22.5MB/s    in 3m 27s  \n",
      "\n",
      "2020-05-19 00:13:35 (13.0 MB/s) - ‘HIGGS.csv.gz’ saved [2816407858/2816407858]\n",
      "\n",
      "--2020-05-19 00:13:35--  http://./\n",
      "Resolving . (.)... failed: No address associated with hostname.\n",
      "wget: unable to resolve host address ‘.’\n",
      "FINISHED --2020-05-19 00:13:35--\n",
      "Total wall clock time: 3m 28s\n",
      "Downloaded: 1 files, 2.6G in 3m 27s (13.0 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name '*.csv.gz' -exec gzip -d {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = sagemaker.session.Session().upload_data('HIGGS.csv',key_prefix='rapids/higgsdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_df = pd.read_csv('HIGGS.csv',names=['col'+str(s) for s in range(29)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col19</th>\n",
       "      <th>col20</th>\n",
       "      <th>col21</th>\n",
       "      <th>col22</th>\n",
       "      <th>col23</th>\n",
       "      <th>col24</th>\n",
       "      <th>col25</th>\n",
       "      <th>col26</th>\n",
       "      <th>col27</th>\n",
       "      <th>col28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col0      col1      col2      col3      col4      col5      col6      col7  \\\n",
       "0     1  0.869293 -0.635082  0.225690  0.327470 -0.689993  0.754202 -0.248573   \n",
       "1     1  0.907542  0.329147  0.359412  1.497970 -0.313010  1.095531 -0.557525   \n",
       "2     1  0.798835  1.470639 -1.635975  0.453773  0.425629  1.104875  1.282322   \n",
       "3     0  1.344385 -0.876626  0.935913  1.992050  0.882454  1.786066 -1.646778   \n",
       "4     1  1.105009  0.321356  1.522401  0.882808 -1.205349  0.681466 -1.070464   \n",
       "\n",
       "       col8      col9  ...     col19     col20     col21     col22     col23  \\\n",
       "0 -1.092064  0.000000  ... -0.010455 -0.045767  3.101961  1.353760  0.979563   \n",
       "1 -1.588230  2.173076  ... -1.138930 -0.000819  0.000000  0.302220  0.833048   \n",
       "2  1.381664  0.000000  ...  1.128848  0.900461  0.000000  0.909753  1.108330   \n",
       "3 -0.942383  0.000000  ... -0.678379 -1.360356  0.000000  0.946652  1.028704   \n",
       "4 -0.921871  0.000000  ... -0.373566  0.113041  0.000000  0.755856  1.361057   \n",
       "\n",
       "      col24     col25     col26     col27     col28  \n",
       "0  0.978076  0.920005  0.721657  0.988751  0.876678  \n",
       "1  0.985700  0.978098  0.779732  0.992356  0.798343  \n",
       "2  0.985692  0.951331  0.803252  0.865924  0.780118  \n",
       "3  0.998656  0.728281  0.869200  1.026736  0.957904  \n",
       "4  0.986610  0.838085  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_df['col0'] = higgs_df['col0'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000000, 29)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higgs_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cudf xgboost script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cudf_xgboost_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cudf_xgboost_example.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from cuml.test.utils import array_equal\n",
    "from cuml.utils.import_utils import has_xgboost\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "    \n",
    "from cuml import ForestInference\n",
    "\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "import cudf\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io, requests\n",
    "from io import StringIO\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "globalstart = time.process_time()\n",
    "print(datetime.datetime.now())\n",
    "# your code here    \n",
    "\n",
    "\n",
    "\n",
    "if has_xgboost():\n",
    "    import xgboost as xgb\n",
    "else:\n",
    "    raise ImportError(\"Please install xgboost using the conda package,\"\n",
    "                      \" Use conda install -c conda-forge xgboost \"\n",
    "                      \"command to install xgboost\")\n",
    "    \n",
    "def train_xgboost_model(X_train, y_train,\n",
    "                        num_rounds, model_path):\n",
    "    # set the xgboost model parameters\n",
    "#     params = {'silent': 1, 'eval_metric':'error',\n",
    "#               'objective':'binary:logistic',\n",
    "#               'max_depth': 25}\n",
    "    params = {'silent': 0, 'tree_method': 'gpu_hist',\n",
    "              'eval_metric': 'auc',\n",
    "              'objective': 'binary:logistic'}\n",
    "    \n",
    "    print(\"in xgboost training\")\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    print(\"loaded dtrain\")\n",
    "    # train the xgboost model\n",
    "    bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "    # save the trained xgboost model\n",
    "    bst.save_model(model_path)\n",
    "\n",
    "    return bst\n",
    "\n",
    "def predict_xgboost_model(X_validation, y_validation, xgb_model):\n",
    "\n",
    "    # predict using the xgboost model\n",
    "    dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "    xgb_preds = xgb_model.predict(dvalidation)\n",
    "\n",
    "    # convert the predicted values from xgboost into class labels\n",
    "    xgb_preds = np.around(xgb_preds)\n",
    "    \n",
    "    return xgb_preds\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    print(\"Loading data\",time.process_time() - globalstart,datetime.datetime.now())\n",
    "    start = time.process_time()\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--num-round', type=int, default=15)\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'HIGGS.csv')\n",
    "    higgs_df = cudf.read_csv(input_data_path,names=['col'+str(s) for s in range(29)])\n",
    "    \n",
    "    print(\"Loading time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "    Y = higgs_df['col0']\n",
    "    X = higgs_df.pop('col0')\n",
    "    \n",
    "    start = time.process_time()\n",
    "    \n",
    "    # Generate some sample data\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X,Y, test_size=args.train_test_split_ratio)\n",
    "    print(\"Split time=\",time.process_time() - start,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    start = time.process_time()\n",
    "    # enter path to the directory where the trained model will be saved\n",
    "    model_path = os.path.join('/opt/ml/processing/train', 'xgb.model')\n",
    "    # This trains and saves the model\n",
    "    num_rounds = args.num_round\n",
    "    xgboost_model = train_xgboost_model(X_train, y_train,\n",
    "                                    num_rounds, model_path)\n",
    "    \n",
    "    print(\"Training time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    \n",
    "    start = time.process_time()\n",
    "    trained_model_preds = predict_xgboost_model(X_validation,\n",
    "                                            y_validation,\n",
    "                                            xgboost_model)\n",
    "    print(\"Validation time=\",time.process_time() - start,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    start = time.process_time()\n",
    "    fm = ForestInference.load(filename=model_path,\n",
    "                          algo='BATCH_TREE_REORG',\n",
    "                          output_class=True,\n",
    "                          threshold=0.50,\n",
    "                          model_type='xgboost')\n",
    "    print(\"fm init time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    \n",
    "    start = time.process_time()\n",
    "    fil_preds = fm.predict(X_validation)\n",
    "    print(\"fm Validation time=\",time.process_time() - start,datetime.datetime.now())\n",
    "\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y_validation.tolist(), fil_preds, pos_label=2)\n",
    "#     print('AUC = ',metrics.auc(fpr, tpr))\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"End\",time.process_time() - globalstart,datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  miniconda-rapids-container-v2-2020-05-20-21-48-07-383\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-21-48-07-383/input/code/cudf_xgboost_example.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-21-48-07-383/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-21-48-07-383/input/code/cudf_xgboost_example.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-21-48-07-383/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]}, 'ProcessingJobName': 'miniconda-rapids-container-v2-2020-05-20-21-48-07-383', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.p3.16xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '497456752804.dkr.ecr.us-east-1.amazonaws.com/miniconda-rapids-container-v2:latest', 'ContainerEntrypoint': ['python', '/opt/ml/processing/input/code/cudf_xgboost_example.py'], 'ContainerArguments': ['--train-test-split-ratio', '0.2', '--num-round', '100']}, 'RoleArn': 'arn:aws:iam::497456752804:role/service-role/AmazonSageMaker-ExecutionRole-20191209T111054', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:497456752804:processing-job/miniconda-rapids-container-v2-2020-05-20-21-48-07-383', 'ProcessingJobStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 5, 20, 21, 48, 7, 712000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 5, 20, 21, 48, 7, 712000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '5172c4dd-6a0e-4e78-b803-b5104c7596c8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5172c4dd-6a0e-4e78-b803-b5104c7596c8', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1736', 'date': 'Wed, 20 May 2020 21:48:07 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor.run(code='cudf_xgboost_example.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source='s3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv',\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2','--num-round','100'], wait=False\n",
    "                     )\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask xgboost in rapids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cudf_dask_xgboost_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cudf_dask_xgboost_example.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from cuml.test.utils import array_equal\n",
    "from cuml.utils.import_utils import has_xgboost\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "    \n",
    "from cuml import ForestInference\n",
    "\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "import cudf\n",
    "\n",
    "import dask\n",
    "import dask_cudf\n",
    "import dask_xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "import subprocess\n",
    "\n",
    "cmd = \"hostname --all-ip-addresses\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "IPADDR = str(output.decode()).split()[0]\n",
    "\n",
    "cluster = LocalCUDACluster(ip=IPADDR)\n",
    "client = Client(cluster)\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io, requests\n",
    "from io import StringIO\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "globalstart = time.process_time()\n",
    "print(datetime.datetime.now())\n",
    "# your code here    \n",
    "\n",
    "\n",
    "\n",
    "if has_xgboost():\n",
    "    import xgboost as xgb\n",
    "else:\n",
    "    raise ImportError(\"Please install xgboost using the conda package,\"\n",
    "                      \" Use conda install -c conda-forge xgboost \"\n",
    "                      \"command to install xgboost\")\n",
    "    \n",
    "def train_xgboost_model(X_train, y_train,\n",
    "                        num_rounds, model_path):\n",
    "\n",
    "    params = {'silent': 0, 'tree_method': 'gpu_hist',\n",
    "              'eval_metric': 'auc',\n",
    "              'objective': 'binary:logistic'}\n",
    "    \n",
    "    print(\"in xgboost training\")\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    print(\"loaded dtrain\")\n",
    "    # train the xgboost model\n",
    "    bst = xgb.train(params, dtrain, num_rounds)\n",
    "    \n",
    "\n",
    "    ## Optional: persist training data into memory\n",
    "    x_train = X_train.persist()\n",
    "    y_train = y_train.persist()\n",
    "\n",
    "    bst = dask_xgboost.train(client, params, x_train, y_train, num_boost_round=params['num_rounds'])\n",
    "\n",
    "    # save the trained xgboost model\n",
    "    bst.save_model(model_path)\n",
    "\n",
    "    return bst\n",
    "\n",
    "def predict_xgboost_model(X_validation, y_validation, xgb_model):\n",
    "\n",
    "    # predict using the xgboost model\n",
    "    dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "    xgb_preds = xgb_model.predict(dvalidation)\n",
    "\n",
    "    # convert the predicted values from xgboost into class labels\n",
    "    xgb_preds = np.around(xgb_preds)\n",
    "    return xgb_preds\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    print(\"Loading data\",time.process_time() - globalstart,datetime.datetime.now())\n",
    "    start = time.process_time()\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--n-partitions', type=int, default=20)\n",
    "    parser.add_argument('--num-round', type=int, default=15)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'HIGGS.csv')\n",
    "    higgs_dask_df = cudf.read_csv(input_data_path,names=['col'+str(s) for s in range(29)])\n",
    "    \n",
    "    dask.dataframe.from_pandas(higgs_df, npartitions=args.n_partitions)\n",
    "    \n",
    "    print(\"Loading time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "    Y = higgs_dask_df['col0']\n",
    "    X = higgs_dask_df.pop('col0')\n",
    "    \n",
    "    start = time.process_time()\n",
    "    \n",
    "    # Generate some sample data\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X,Y, test_size=args.train_test_split_ratio)\n",
    "    print(\"Split time=\",time.process_time() - start,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    start = time.process_time()\n",
    "    # enter path to the directory where the trained model will be saved\n",
    "    model_path = os.path.join('/opt/ml/processing/train', 'xgb.model')\n",
    "    # This trains and saves the model\n",
    "    num_rounds = args.num_round\n",
    "    xgboost_model = train_xgboost_model(X_train, y_train,\n",
    "                                    num_rounds, model_path)\n",
    "    \n",
    "    print(\"Training time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    \n",
    "    start = time.process_time()\n",
    "    trained_model_preds = predict_xgboost_model(X_validation,\n",
    "                                            y_validation,\n",
    "                                            xgboost_model)\n",
    "    print(\"Validation time=\",time.process_time() - start,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    start = time.process_time()\n",
    "    fm = ForestInference.load(filename=model_path,\n",
    "                          algo='BATCH_TREE_REORG',\n",
    "                          output_class=True,\n",
    "                          threshold=0.50,\n",
    "                          model_type='xgboost')\n",
    "    print(\"fm init time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    \n",
    "    start = time.process_time()\n",
    "    fil_preds = fm.predict(X_validation)\n",
    "    print(\"fm Validation time=\",time.process_time() - start,datetime.datetime.now())\n",
    "    print(type(y_validation))\n",
    "    print(type(fil_preds))\n",
    "    print(type(np.asarray(fil_preds)))\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_validation, np.asarray(fil_preds), pos_label=2)\n",
    "    print('AUC = ',metrics.auc(fpr, tpr))\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"End\",time.process_time() - globalstart,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  miniconda-rapids-container-v2-2020-05-20-22-27-49-922\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-22-27-49-922/input/code/cudf_xgboost_example.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-22-27-49-922/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".......................................................\u001b[34m2020-05-20 22:37:03.831143\u001b[0m\n",
      "\u001b[34mLoading data 0.39301802799999974 2020-05-20 22:37:04.224183\u001b[0m\n",
      "\u001b[34m/conda/lib/python3.6/site-packages/fsspec/implementations/local.py:33: FutureWarning: The default value of auto_mkdir=True has been deprecated and will be changed to auto_mkdir=False by default in a future release.\n",
      "  FutureWarning,\u001b[0m\n",
      "\u001b[34mLoading time= 12.109400484999998 2020-05-20 22:38:07.216194\u001b[0m\n",
      "\u001b[34mSplit time= 1.1940300110000006 2020-05-20 22:38:08.914799\u001b[0m\n",
      "\u001b[34min xgboost training\u001b[0m\n",
      "\u001b[34mloaded dtrain\u001b[0m\n",
      "\u001b[34m[22:38:09] WARNING: /conda/conda-bld/xgboost_1585677082603/work/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTraining time= 0.8398186689999996 2020-05-20 22:38:09.823989\u001b[0m\n",
      "\u001b[34mValidation time= 5.366363380999999 2020-05-20 22:38:09.997099\u001b[0m\n",
      "\u001b[34mfm init time= 0.016314094000001944 2020-05-20 22:38:09.997490\u001b[0m\n",
      "\u001b[34m/conda/lib/python3.6/site-packages/cuml/utils/input_utils.py:188: UserWarning: Expected row ('C') major order, but got the opposite. Converting data, this will result in additional memory utilization.\n",
      "  warnings.warn(\"Expected \" + order_to_str(order) + \" major order, \"\u001b[0m\n",
      "\u001b[34mfm Validation time= 0.22041783999999964 2020-05-20 22:38:10.002213\u001b[0m\n",
      "\u001b[34m-------------------------------\u001b[0m\n",
      "\u001b[34mEnd 20.145665885 2020-05-20 22:38:10.002251\u001b[0m\n",
      "\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-22-27-49-922/input/code/cudf_xgboost_example.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-497456752804/miniconda-rapids-container-v2-2020-05-20-22-27-49-922/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]}, 'ProcessingJobName': 'miniconda-rapids-container-v2-2020-05-20-22-27-49-922', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.p3.16xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '497456752804.dkr.ecr.us-east-1.amazonaws.com/miniconda-rapids-container-v2:latest', 'ContainerEntrypoint': ['python', '/opt/ml/processing/input/code/cudf_xgboost_example.py'], 'ContainerArguments': ['--train-test-split-ratio', '0.2', '--n-partitions', '320', '--num-round', '100']}, 'RoleArn': 'arn:aws:iam::497456752804:role/service-role/AmazonSageMaker-ExecutionRole-20191209T111054', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:497456752804:processing-job/miniconda-rapids-container-v2-2020-05-20-22-27-49-922', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2020, 5, 20, 22, 38, 18, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2020, 5, 20, 22, 33, 36, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2020, 5, 20, 22, 38, 18, 388000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 5, 20, 22, 27, 50, 610000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '412c4bc3-48f9-45ce-ba43-e057fa932653', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '412c4bc3-48f9-45ce-ba43-e057fa932653', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1827', 'date': 'Wed, 20 May 2020 22:38:47 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor.run(code='cudf_xgboost_example.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source='s3://sagemaker-us-east-1-497456752804/rapids/higgsdata/HIGGS.csv',\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2','--n-partitions','320','--num-round','100']\n",
    "                     )\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run only once if doing repeated testing...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-us-east-1-497456752804'\n",
    "prefix = 'sagemaker/DEMO-xgboost-churn'\n",
    "\n",
    "train_data, validation_data, test_data = np.split(higgs_df.sample(frac=1), [int(0.8 * len(higgs_df)), int(0.99 * len(higgs_df))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.drop('col0', axis=1).to_csv('test.csv', header=False, index=False) # Testing for performance benchmark here. For Actual use cases, please use a hold out set (see test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using SageMaker's Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-20 14:37:48 Starting - Starting the training job...\n",
      "2020-05-20 14:37:49 Starting - Launching requested ML instances.........\n",
      "2020-05-20 14:39:33 Starting - Preparing the instances for training............\n",
      "2020-05-20 14:41:30 Downloading - Downloading input data.........\n",
      "2020-05-20 14:43:11 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\n",
      "2020-05-20 14:43:26 Training - Training image download completed. Training in progress.\u001b[34m[14:44:02] 8800000x28 matrix with 246400000 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:44:10] 2090000x28 matrix with 58520000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 8800000 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 2090000 rows\u001b[0m\n",
      "\u001b[34m[14:44:10] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.74277#011validation-auc:0.742308\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.755501#011validation-auc:0.754967\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.763788#011validation-auc:0.763309\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.769154#011validation-auc:0.768695\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.775612#011validation-auc:0.775092\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.781599#011validation-auc:0.781122\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.784788#011validation-auc:0.784247\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.788138#011validation-auc:0.787647\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.790498#011validation-auc:0.79\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.792688#011validation-auc:0.792192\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.794474#011validation-auc:0.79397\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.795761#011validation-auc:0.795217\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.797241#011validation-auc:0.796685\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.798613#011validation-auc:0.798021\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.799754#011validation-auc:0.799143\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.800704#011validation-auc:0.800138\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.801738#011validation-auc:0.801152\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.802687#011validation-auc:0.802111\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.803498#011validation-auc:0.802897\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.804026#011validation-auc:0.803414\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.804505#011validation-auc:0.803863\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.805151#011validation-auc:0.804497\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.805922#011validation-auc:0.805257\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.806234#011validation-auc:0.80556\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.806751#011validation-auc:0.806064\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.807342#011validation-auc:0.80663\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.807931#011validation-auc:0.807188\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.808429#011validation-auc:0.807658\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.808968#011validation-auc:0.808186\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.80995#011validation-auc:0.809149\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.810231#011validation-auc:0.809404\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.810622#011validation-auc:0.809793\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.811201#011validation-auc:0.810343\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.811713#011validation-auc:0.81085\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.812026#011validation-auc:0.81116\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.812173#011validation-auc:0.8113\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.81244#011validation-auc:0.811544\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.81288#011validation-auc:0.811976\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.813279#011validation-auc:0.812363\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.813607#011validation-auc:0.812662\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.813895#011validation-auc:0.812939\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.814218#011validation-auc:0.813242\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.814398#011validation-auc:0.813417\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.814713#011validation-auc:0.813719\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.815001#011validation-auc:0.814\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.815155#011validation-auc:0.814139\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.815395#011validation-auc:0.814371\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.815647#011validation-auc:0.814608\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.815927#011validation-auc:0.814852\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.816242#011validation-auc:0.815154\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.816466#011validation-auc:0.815364\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.816699#011validation-auc:0.815576\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.816865#011validation-auc:0.81573\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.816961#011validation-auc:0.815817\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.817424#011validation-auc:0.81627\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.817563#011validation-auc:0.816402\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.817811#011validation-auc:0.816636\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.818103#011validation-auc:0.816901\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.818204#011validation-auc:0.816987\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.818475#011validation-auc:0.81724\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.818722#011validation-auc:0.817478\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.818977#011validation-auc:0.817721\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.819225#011validation-auc:0.817951\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.819372#011validation-auc:0.818081\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.81946#011validation-auc:0.81816\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.819613#011validation-auc:0.818297\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.819798#011validation-auc:0.818464\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.820096#011validation-auc:0.818757\u001b[0m\n",
      "\u001b[34m[68]#011train-auc:0.820254#011validation-auc:0.818892\u001b[0m\n",
      "\u001b[34m[69]#011train-auc:0.820535#011validation-auc:0.819172\u001b[0m\n",
      "\u001b[34m[70]#011train-auc:0.820599#011validation-auc:0.819226\u001b[0m\n",
      "\u001b[34m[71]#011train-auc:0.820718#011validation-auc:0.819335\u001b[0m\n",
      "\u001b[34m[72]#011train-auc:0.821054#011validation-auc:0.819653\u001b[0m\n",
      "\u001b[34m[73]#011train-auc:0.821142#011validation-auc:0.819727\u001b[0m\n",
      "\u001b[34m[74]#011train-auc:0.821233#011validation-auc:0.819808\u001b[0m\n",
      "\u001b[34m[75]#011train-auc:0.821417#011validation-auc:0.819979\u001b[0m\n",
      "\u001b[34m[76]#011train-auc:0.821568#011validation-auc:0.82012\u001b[0m\n",
      "\u001b[34m[77]#011train-auc:0.821629#011validation-auc:0.820165\u001b[0m\n",
      "\u001b[34m[78]#011train-auc:0.82169#011validation-auc:0.820214\u001b[0m\n",
      "\u001b[34m[79]#011train-auc:0.821769#011validation-auc:0.820269\u001b[0m\n",
      "\u001b[34m[80]#011train-auc:0.821973#011validation-auc:0.82046\u001b[0m\n",
      "\u001b[34m[81]#011train-auc:0.822126#011validation-auc:0.820589\u001b[0m\n",
      "\u001b[34m[82]#011train-auc:0.822217#011validation-auc:0.820665\u001b[0m\n",
      "\u001b[34m[83]#011train-auc:0.822387#011validation-auc:0.820815\u001b[0m\n",
      "\u001b[34m[84]#011train-auc:0.822547#011validation-auc:0.820954\u001b[0m\n",
      "\u001b[34m[85]#011train-auc:0.822817#011validation-auc:0.821212\u001b[0m\n",
      "\u001b[34m[86]#011train-auc:0.822895#011validation-auc:0.821285\u001b[0m\n",
      "\u001b[34m[87]#011train-auc:0.823002#011validation-auc:0.82138\u001b[0m\n",
      "\u001b[34m[88]#011train-auc:0.823166#011validation-auc:0.821536\u001b[0m\n",
      "\u001b[34m[89]#011train-auc:0.823509#011validation-auc:0.821869\u001b[0m\n",
      "\u001b[34m[90]#011train-auc:0.823796#011validation-auc:0.82215\u001b[0m\n",
      "\u001b[34m[91]#011train-auc:0.824017#011validation-auc:0.822364\u001b[0m\n",
      "\u001b[34m[92]#011train-auc:0.824208#011validation-auc:0.822545\u001b[0m\n",
      "\u001b[34m[93]#011train-auc:0.824404#011validation-auc:0.822739\u001b[0m\n",
      "\u001b[34m[94]#011train-auc:0.824522#011validation-auc:0.822835\u001b[0m\n",
      "\u001b[34m[95]#011train-auc:0.824619#011validation-auc:0.822926\u001b[0m\n",
      "\u001b[34m[96]#011train-auc:0.82486#011validation-auc:0.823159\u001b[0m\n",
      "\u001b[34m[97]#011train-auc:0.825023#011validation-auc:0.82331\u001b[0m\n",
      "\n",
      "2020-05-20 14:57:28 Uploading - Uploading generated training model\u001b[34m[98]#011train-auc:0.82519#011validation-auc:0.823473\u001b[0m\n",
      "\u001b[34m[99]#011train-auc:0.825498#011validation-auc:0.823778\u001b[0m\n",
      "\n",
      "2020-05-20 14:57:35 Completed - Training job completed\n",
      "Training seconds: 965\n",
      "Billable seconds: 965\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.p3.8xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "# params = {'silent': 0, 'tree_method': 'gpu_hist',\n",
    "#           'eval_metric': 'auc',\n",
    "#           'objective': 'binary:logistic',\n",
    "#               'num_round':100}\n",
    "\n",
    "xgb.set_hyperparameters(silent=0,\n",
    "                        eval_metric='auc',\n",
    "                        num_round=100,\n",
    "                        objective='binary:logistic')\n",
    "\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SM Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Using already existing model: sagemaker-xgboost-2020-05-20-14-37-47-915\n"
     ]
    }
   ],
   "source": [
    "sm_transformer = xgb.transformer(instance_count =1,\n",
    "                                 instance_type ='ml.p3.16xlarge',\n",
    "                                )\n",
    "\n",
    "# start a transform job\n",
    "input_location = 's3://{}/{}/test/'.format(bucket, prefix)\n",
    "sm_transformer.transform(input_location, split_type='Line',content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count, instance_type, strategy=None, assemble_with=None, output_path=None, output_kms_key=None, accept=None, env=None, max_concurrent_transforms=None, max_payload=None, tags=None, role=None, volume_kms_key=None, vpc_config_override='VPC_CONFIG_DEFAULT', enable_network_isolation=None, model_name=Non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudf_dask_xgboost_example.py\r\n",
      "cudf_xgboost_example.py\r\n",
      "docker\r\n",
      "forest_inference_demo.ipynb\r\n",
      "HIGGS.csv\r\n",
      "preprocessing.py\r\n",
      "RapidsAI based Data Science using SageMaker processing.ipynb\r\n",
      "test.csv\r\n",
      "tips.csv\r\n",
      "train.csv\r\n",
      "validation.csv\r\n",
      "x.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.0-py3-none-manylinux2010_x86_64.whl (127.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 127.6 MB 19 kB/s s eta 0:00:01   |▌                               | 1.9 MB 15.3 MB/s eta 0:00:09\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.18.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster({'nthread': 4})  # init model\n",
    "bst.load_model('xgb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x7ff9ba2e0860>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>Node</th>\n",
       "      <th>ID</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Split</th>\n",
       "      <th>Yes</th>\n",
       "      <th>No</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>f0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-2</td>\n",
       "      <td>0-1</td>\n",
       "      <td>8.768354e+06</td>\n",
       "      <td>2.200000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.999994e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.999995e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1-0</td>\n",
       "      <td>f0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1-1</td>\n",
       "      <td>1-2</td>\n",
       "      <td>1-1</td>\n",
       "      <td>4.812176e+06</td>\n",
       "      <td>2.013302e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.646429e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>95-0</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.984138e-02</td>\n",
       "      <td>1.532724e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>96-0</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.802034e-02</td>\n",
       "      <td>2.041205e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>97-0</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626312e-02</td>\n",
       "      <td>2.058103e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>98-0</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.466685e-02</td>\n",
       "      <td>2.073617e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99-0</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.975548e-02</td>\n",
       "      <td>1.531854e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tree  Node    ID Feature  Split  Yes   No Missing          Gain  \\\n",
       "0       0     0   0-0      f0    0.5  0-1  0-2     0-1  8.768354e+06   \n",
       "1       0     1   0-1    Leaf    NaN  NaN  NaN     NaN -5.999994e-01   \n",
       "2       0     2   0-2    Leaf    NaN  NaN  NaN     NaN  5.999995e-01   \n",
       "3       1     0   1-0      f0    0.5  1-1  1-2     1-1  4.812176e+06   \n",
       "4       1     1   1-1    Leaf    NaN  NaN  NaN     NaN -4.646429e-01   \n",
       "..    ...   ...   ...     ...    ...  ...  ...     ...           ...   \n",
       "199    95     0  95-0    Leaf    NaN  NaN  NaN     NaN -4.984138e-02   \n",
       "200    96     0  96-0    Leaf    NaN  NaN  NaN     NaN  1.802034e-02   \n",
       "201    97     0  97-0    Leaf    NaN  NaN  NaN     NaN  1.626312e-02   \n",
       "202    98     0  98-0    Leaf    NaN  NaN  NaN     NaN  1.466685e-02   \n",
       "203    99     0  99-0    Leaf    NaN  NaN  NaN     NaN -4.975548e-02   \n",
       "\n",
       "            Cover  \n",
       "0    2.200000e+06  \n",
       "1    0.000000e+00  \n",
       "2    0.000000e+00  \n",
       "3    2.013302e+06  \n",
       "4    0.000000e+00  \n",
       "..            ...  \n",
       "199  1.532724e+00  \n",
       "200  2.041205e+00  \n",
       "201  2.058103e+00  \n",
       "202  2.073617e+00  \n",
       "203  1.531854e+00  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col19</th>\n",
       "      <th>col20</th>\n",
       "      <th>col21</th>\n",
       "      <th>col22</th>\n",
       "      <th>col23</th>\n",
       "      <th>col24</th>\n",
       "      <th>col25</th>\n",
       "      <th>col26</th>\n",
       "      <th>col27</th>\n",
       "      <th>col28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8300971</th>\n",
       "      <td>1</td>\n",
       "      <td>0.484791</td>\n",
       "      <td>0.287267</td>\n",
       "      <td>0.220142</td>\n",
       "      <td>1.104423</td>\n",
       "      <td>-1.204572</td>\n",
       "      <td>0.742843</td>\n",
       "      <td>0.650556</td>\n",
       "      <td>1.483669</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692448</td>\n",
       "      <td>0.109711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948819</td>\n",
       "      <td>0.943823</td>\n",
       "      <td>0.987724</td>\n",
       "      <td>0.905025</td>\n",
       "      <td>0.914164</td>\n",
       "      <td>0.750882</td>\n",
       "      <td>0.701774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924625</th>\n",
       "      <td>0</td>\n",
       "      <td>0.389077</td>\n",
       "      <td>-0.048753</td>\n",
       "      <td>-1.349666</td>\n",
       "      <td>1.790137</td>\n",
       "      <td>1.715823</td>\n",
       "      <td>1.294318</td>\n",
       "      <td>-0.801121</td>\n",
       "      <td>-0.210050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.839114</td>\n",
       "      <td>-0.514668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.075798</td>\n",
       "      <td>1.022699</td>\n",
       "      <td>0.975776</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>0.486526</td>\n",
       "      <td>0.769174</td>\n",
       "      <td>0.742101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842886</th>\n",
       "      <td>1</td>\n",
       "      <td>1.816182</td>\n",
       "      <td>-0.128618</td>\n",
       "      <td>-0.182235</td>\n",
       "      <td>2.456141</td>\n",
       "      <td>0.104298</td>\n",
       "      <td>1.666152</td>\n",
       "      <td>-2.294388</td>\n",
       "      <td>-1.512280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.577739</td>\n",
       "      <td>1.487558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840247</td>\n",
       "      <td>1.267690</td>\n",
       "      <td>0.983190</td>\n",
       "      <td>1.229591</td>\n",
       "      <td>0.881115</td>\n",
       "      <td>1.243128</td>\n",
       "      <td>1.293838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191959</th>\n",
       "      <td>0</td>\n",
       "      <td>0.851358</td>\n",
       "      <td>0.785939</td>\n",
       "      <td>-0.030758</td>\n",
       "      <td>0.909259</td>\n",
       "      <td>-1.434206</td>\n",
       "      <td>1.181642</td>\n",
       "      <td>-1.972563</td>\n",
       "      <td>-0.522163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614163</td>\n",
       "      <td>0.510358</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.879423</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>1.161848</td>\n",
       "      <td>0.692461</td>\n",
       "      <td>0.736917</td>\n",
       "      <td>0.592077</td>\n",
       "      <td>0.647699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8839804</th>\n",
       "      <td>0</td>\n",
       "      <td>0.935726</td>\n",
       "      <td>0.956383</td>\n",
       "      <td>1.527950</td>\n",
       "      <td>0.219544</td>\n",
       "      <td>-0.133253</td>\n",
       "      <td>0.625036</td>\n",
       "      <td>-0.605056</td>\n",
       "      <td>-0.739481</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456848</td>\n",
       "      <td>-0.266622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819641</td>\n",
       "      <td>0.765392</td>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.717036</td>\n",
       "      <td>1.558316</td>\n",
       "      <td>1.055638</td>\n",
       "      <td>0.910037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8401292</th>\n",
       "      <td>1</td>\n",
       "      <td>1.052485</td>\n",
       "      <td>0.711917</td>\n",
       "      <td>-1.042828</td>\n",
       "      <td>2.480450</td>\n",
       "      <td>-0.657692</td>\n",
       "      <td>1.839473</td>\n",
       "      <td>0.156431</td>\n",
       "      <td>0.968655</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009622</td>\n",
       "      <td>1.398772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341178</td>\n",
       "      <td>0.708616</td>\n",
       "      <td>0.999462</td>\n",
       "      <td>0.469504</td>\n",
       "      <td>1.399658</td>\n",
       "      <td>1.469215</td>\n",
       "      <td>1.052727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014379</th>\n",
       "      <td>0</td>\n",
       "      <td>1.062002</td>\n",
       "      <td>1.161891</td>\n",
       "      <td>-1.648737</td>\n",
       "      <td>0.752124</td>\n",
       "      <td>1.300429</td>\n",
       "      <td>0.688703</td>\n",
       "      <td>-1.218008</td>\n",
       "      <td>0.246304</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.872647</td>\n",
       "      <td>-1.365351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861246</td>\n",
       "      <td>0.992491</td>\n",
       "      <td>0.980291</td>\n",
       "      <td>1.097236</td>\n",
       "      <td>0.512228</td>\n",
       "      <td>1.440075</td>\n",
       "      <td>1.865075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247014</th>\n",
       "      <td>0</td>\n",
       "      <td>1.416490</td>\n",
       "      <td>0.988524</td>\n",
       "      <td>-1.103863</td>\n",
       "      <td>0.703794</td>\n",
       "      <td>1.465887</td>\n",
       "      <td>1.082981</td>\n",
       "      <td>0.574308</td>\n",
       "      <td>0.962556</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320176</td>\n",
       "      <td>0.427676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803851</td>\n",
       "      <td>1.061422</td>\n",
       "      <td>1.016638</td>\n",
       "      <td>1.107646</td>\n",
       "      <td>1.935393</td>\n",
       "      <td>1.084115</td>\n",
       "      <td>0.890553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882761</th>\n",
       "      <td>1</td>\n",
       "      <td>0.611982</td>\n",
       "      <td>-0.580540</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>1.412994</td>\n",
       "      <td>-1.164767</td>\n",
       "      <td>0.751637</td>\n",
       "      <td>-0.890242</td>\n",
       "      <td>-0.776624</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.124993</td>\n",
       "      <td>0.644091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976866</td>\n",
       "      <td>0.565791</td>\n",
       "      <td>1.108988</td>\n",
       "      <td>0.659875</td>\n",
       "      <td>0.723932</td>\n",
       "      <td>0.951845</td>\n",
       "      <td>0.902022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380721</th>\n",
       "      <td>0</td>\n",
       "      <td>0.548478</td>\n",
       "      <td>-1.472695</td>\n",
       "      <td>0.615758</td>\n",
       "      <td>0.814628</td>\n",
       "      <td>-1.398086</td>\n",
       "      <td>0.788463</td>\n",
       "      <td>0.364379</td>\n",
       "      <td>-0.359177</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690871</td>\n",
       "      <td>0.952068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.886708</td>\n",
       "      <td>0.988585</td>\n",
       "      <td>0.721462</td>\n",
       "      <td>0.808924</td>\n",
       "      <td>0.750983</td>\n",
       "      <td>0.679908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col0      col1      col2      col3      col4      col5      col6  \\\n",
       "8300971      1  0.484791  0.287267  0.220142  1.104423 -1.204572  0.742843   \n",
       "10924625     0  0.389077 -0.048753 -1.349666  1.790137  1.715823  1.294318   \n",
       "8842886      1  1.816182 -0.128618 -0.182235  2.456141  0.104298  1.666152   \n",
       "5191959      0  0.851358  0.785939 -0.030758  0.909259 -1.434206  1.181642   \n",
       "8839804      0  0.935726  0.956383  1.527950  0.219544 -0.133253  0.625036   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8401292      1  1.052485  0.711917 -1.042828  2.480450 -0.657692  1.839473   \n",
       "5014379      0  1.062002  1.161891 -1.648737  0.752124  1.300429  0.688703   \n",
       "8247014      0  1.416490  0.988524 -1.103863  0.703794  1.465887  1.082981   \n",
       "10882761     1  0.611982 -0.580540 -0.013003  1.412994 -1.164767  0.751637   \n",
       "1380721      0  0.548478 -1.472695  0.615758  0.814628 -1.398086  0.788463   \n",
       "\n",
       "              col7      col8      col9  ...     col19     col20     col21  \\\n",
       "8300971   0.650556  1.483669  2.173076  ...  0.692448  0.109711  0.000000   \n",
       "10924625 -0.801121 -0.210050  0.000000  ... -0.839114 -0.514668  0.000000   \n",
       "8842886  -2.294388 -1.512280  0.000000  ...  1.577739  1.487558  0.000000   \n",
       "5191959  -1.972563 -0.522163  0.000000  ...  0.614163  0.510358  3.101961   \n",
       "8839804  -0.605056 -0.739481  1.086538  ... -0.456848 -0.266622  0.000000   \n",
       "...            ...       ...       ...  ...       ...       ...       ...   \n",
       "8401292   0.156431  0.968655  2.173076  ... -0.009622  1.398772  0.000000   \n",
       "5014379  -1.218008  0.246304  2.173076  ... -1.872647 -1.365351  0.000000   \n",
       "8247014   0.574308  0.962556  2.173076  ...  0.320176  0.427676  0.000000   \n",
       "10882761 -0.890242 -0.776624  2.173076  ... -2.124993  0.644091  0.000000   \n",
       "1380721   0.364379 -0.359177  1.086538  ... -0.690871  0.952068  0.000000   \n",
       "\n",
       "             col22     col23     col24     col25     col26     col27     col28  \n",
       "8300971   0.948819  0.943823  0.987724  0.905025  0.914164  0.750882  0.701774  \n",
       "10924625  1.075798  1.022699  0.975776  0.896829  0.486526  0.769174  0.742101  \n",
       "8842886   0.840247  1.267690  0.983190  1.229591  0.881115  1.243128  1.293838  \n",
       "5191959   0.879423  0.810431  1.161848  0.692461  0.736917  0.592077  0.647699  \n",
       "8839804   0.819641  0.765392  0.979729  0.717036  1.558316  1.055638  0.910037  \n",
       "...            ...       ...       ...       ...       ...       ...       ...  \n",
       "8401292   0.341178  0.708616  0.999462  0.469504  1.399658  1.469215  1.052727  \n",
       "5014379   0.861246  0.992491  0.980291  1.097236  0.512228  1.440075  1.865075  \n",
       "8247014   0.803851  1.061422  1.016638  1.107646  1.935393  1.084115  0.890553  \n",
       "10882761  0.976866  0.565791  1.108988  0.659875  0.723932  0.951845  0.902022  \n",
       "1380721   0.899416  0.886708  0.988585  0.721462  0.808924  0.750983  0.679908  \n",
       "\n",
       "[110000 rows x 29 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalidation = xgb.DMatrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[23:27:00] /workspace/src/learner.cc:1062: Check failed: learner_model_param_.num_feature == p_fmat->Info().num_col_ (1 vs. 29) : Number of columns does not match number of features in booster.\nStack trace:\n  [bt] (0) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xa0c64) [0x7ff40e9e5c64]\n  [bt] (1) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x195440) [0x7ff40eada440]\n  [bt] (2) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x198a9d) [0x7ff40eadda9d]\n  [bt] (3) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredict+0xd9) [0x7ff40e9d6749]\n  [bt] (4) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7ff9e41d5ec0]\n  [bt] (5) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7ff9e41d587d]\n  [bt] (6) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ff9e43eae2e]\n  [bt] (7) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865) [0x7ff9e43eb865]\n  [bt] (8) /home/ec2-user/anaconda3/envs/python3/bin/python(_PyObject_FastCallDict+0x8b) [0x5654e9e7fd7b]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-d735db4f1e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[1;32m   1577\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m   1580\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [23:27:00] /workspace/src/learner.cc:1062: Check failed: learner_model_param_.num_feature == p_fmat->Info().num_col_ (1 vs. 29) : Number of columns does not match number of features in booster.\nStack trace:\n  [bt] (0) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xa0c64) [0x7ff40e9e5c64]\n  [bt] (1) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x195440) [0x7ff40eada440]\n  [bt] (2) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x198a9d) [0x7ff40eadda9d]\n  [bt] (3) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredict+0xd9) [0x7ff40e9d6749]\n  [bt] (4) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7ff9e41d5ec0]\n  [bt] (5) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7ff9e41d587d]\n  [bt] (6) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ff9e43eae2e]\n  [bt] (7) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865) [0x7ff9e43eb865]\n  [bt] (8) /home/ec2-user/anaconda3/envs/python3/bin/python(_PyObject_FastCallDict+0x8b) [0x5654e9e7fd7b]\n\n"
     ]
    }
   ],
   "source": [
    "xgb_preds = bst.predict(dvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col0',\n",
       " 'col1',\n",
       " 'col2',\n",
       " 'col3',\n",
       " 'col4',\n",
       " 'col5',\n",
       " 'col6',\n",
       " 'col7',\n",
       " 'col8',\n",
       " 'col9',\n",
       " 'col10',\n",
       " 'col11',\n",
       " 'col12',\n",
       " 'col13',\n",
       " 'col14',\n",
       " 'col15',\n",
       " 'col16',\n",
       " 'col17',\n",
       " 'col18',\n",
       " 'col19',\n",
       " 'col20',\n",
       " 'col21',\n",
       " 'col22',\n",
       " 'col23',\n",
       " 'col24',\n",
       " 'col25',\n",
       " 'col26',\n",
       " 'col27',\n",
       " 'col28']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: \\ ^C\n",
      "failed\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c rapidsai -c nvidia -c conda-forge \\\n",
    "    -c defaults rapids=0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==0.90\n",
      "  Downloading xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 142.8 MB 63.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost==0.90) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost==0.90) (1.18.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[00:03:12] /workspace/src/learner.cc:846: Check failed: header == serialisation_header_: \n\n  If you are loading a serialized model (like pickle in Python) generated by older\n  XGBoost, please export the model by calling `Booster.save_model` from that version\n  first, then load it back in current version.  There's a simple script for helping\n  the process. See:\n\n    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n\n  for reference to the script, and more details about differences between saving model and\n  serializing.\n\n\nStack trace:\n  [bt] (0) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xa0c64) [0x7ff40e9e5c64]\n  [bt] (1) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x1b2d11) [0x7ff40eaf7d11]\n  [bt] (2) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterUnserializeFromBuffer+0x4a) [0x7ff40e9d460a]\n  [bt] (3) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7ff9e41d5ec0]\n  [bt] (4) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7ff9e41d587d]\n  [bt] (5) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ff9e43eae2e]\n  [bt] (6) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865) [0x7ff9e43eb865]\n  [bt] (7) /home/ec2-user/anaconda3/envs/python3/bin/python(_PyObject_FastCallDict+0x8b) [0x5654e9e7fd7b]\n  [bt] (8) /home/ec2-user/anaconda3/envs/python3/bin/python(+0x19e7ce) [0x5654e9f0f7ce]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-313-774df58c1727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgboost-model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \"\"\"\n\u001b[1;32m   1211\u001b[0m         \u001b[0mPredict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mthread\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mctype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUMPY_TO_CTYPES_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected {} pointer'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [00:03:12] /workspace/src/learner.cc:846: Check failed: header == serialisation_header_: \n\n  If you are loading a serialized model (like pickle in Python) generated by older\n  XGBoost, please export the model by calling `Booster.save_model` from that version\n  first, then load it back in current version.  There's a simple script for helping\n  the process. See:\n\n    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n\n  for reference to the script, and more details about differences between saving model and\n  serializing.\n\n\nStack trace:\n  [bt] (0) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xa0c64) [0x7ff40e9e5c64]\n  [bt] (1) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x1b2d11) [0x7ff40eaf7d11]\n  [bt] (2) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterUnserializeFromBuffer+0x4a) [0x7ff40e9d460a]\n  [bt] (3) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7ff9e41d5ec0]\n  [bt] (4) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7ff9e41d587d]\n  [bt] (5) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ff9e43eae2e]\n  [bt] (6) /home/ec2-user/anaconda3/envs/python3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865) [0x7ff9e43eb865]\n  [bt] (7) /home/ec2-user/anaconda3/envs/python3/bin/python(_PyObject_FastCallDict+0x8b) [0x5654e9e7fd7b]\n  [bt] (8) /home/ec2-user/anaconda3/envs/python3/bin/python(+0x19e7ce) [0x5654e9f0f7ce]\n\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl \n",
    "model = pkl.load(open('xgboost-model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
